{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to GraphDocument and insert into Neo4j -- Default System Prompt\n",
    "\n",
    "- With help from LLM but we only limited to small amount of data\n",
    "- Let LLM create graph schema with `default system Prompt`\n",
    "- We only show here an example of creating schema of `EntityType=\"Individual\"`, the reader is encourage to repeat the example for `EntityType=\"Entity\"` as excercise\n",
    "\n",
    "\n",
    "\n",
    "**Important Note:**\n",
    "\n",
    "```python\n",
    "# Allowed nodes and relationships\n",
    "allowed_nodes = [\"Person\", \"Alias\", \"Address\", \"Program\", \"IdentityDocument\"]\n",
    "allowed_relationships = [\"HAS_ALIAS\", \"HAS_ADDRESS\",\"SANCTIONED_BY\", \"HAS_DOCUMENT\" ]\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=allowed_nodes,\n",
    "    allowed_relationships=allowed_relationships,\n",
    "    node_properties=True,\n",
    "    relationship_properties=True\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "- **Allowed Nodes & Relationships:** We explicitly define which node types (`Person`, `Alias`, `Address`, etc.) and relationship types (`HAS_ALIAS`, `HAS_ADDRESS`, etc.) can be extracted.\n",
    "- **Property Extraction:** Setting `node_properties=True` and `relationship_properties=True` ensures that the LLM populates relevant attributes for each node and relationship.\n",
    "- **Controlled Graph Generation:** By restricting the structure, we prevent unwanted or irrelevant node types and relationships from being created.\n",
    "\n",
    "\n",
    "```python\n",
    "# **Step 2: Insert new graph data**\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=False, include_source=False)\n",
    "```\n",
    "\n",
    "- **`baseEntityLabel=False`** (to prevent unnecessary indexing):  \n",
    "  - If `True`, adds a secondary `__Entity__` label to every node.  \n",
    "  - This label is indexed, improving import speed and performance.  \n",
    "  - **We set it to `False` to keep our database cleaner and avoid extra indexing.**\n",
    "\n",
    "- **`include_source=False`** (we set it to `False` to avoid `MENTIONS` relationships in our graph):  \n",
    "  - If `True`, stores the original source document and links it to the created nodes using the `MENTIONS` relationship.  \n",
    "  - This helps trace back the origin of extracted information.  \n",
    "  - If no explicit `id` is available in the source metadata, an MD5 hash of `page_content` is used for merging.  \n",
    "  - **Since we do not want `MENTIONS` in our graph, we explicitly set it to `False`.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "load_dotenv('../.env',override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old graph deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 50/50 [01:26<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New graph data successfully added to Neo4j!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "\n",
    "# Initialize Neo4jGraph (LangChain handles the connection)\n",
    "graph = Neo4jGraph(url=NEO4J_URI,username=NEO4J_USER,password=NEO4J_PASSWORD,enhanced_schema=True)\n",
    "\n",
    "\n",
    "# **Step 1: Delete old graph before inserting new data**\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(\"Old graph deleted.\")\n",
    "\n",
    "\n",
    "# Allowed nodes and relationships\n",
    "allowed_nodes = [\"Person\", \"Alias\", \"Address\", \"Program\", \"IdentityDocument\"]\n",
    "allowed_relationships = [\"HAS_ALIAS\", \"HAS_ADDRESS\",\"SANCTIONED_BY\", \"HAS_DOCUMENT\" ]\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=allowed_nodes,\n",
    "    allowed_relationships=allowed_relationships,\n",
    "    node_properties=True,\n",
    "    relationship_properties=True\n",
    ")\n",
    "\n",
    "# Load JSON data\n",
    "with open(\"ofac_data_small.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)[\"individuals\"]\n",
    "\n",
    "# Function to process text\n",
    "def process_text(text: str):\n",
    "    doc = Document(page_content=text)\n",
    "    return llm_transformer.convert_to_graph_documents([doc])\n",
    "\n",
    "# Transform data using LLMGraphTransformer with parallelization\n",
    "graph_documents = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_text, json.dumps(entity)) for entity in data]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing documents\"):\n",
    "        graph_documents.extend(future.result())\n",
    "\n",
    "# **Step 2: Insert new graph data**\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=False, include_source=False)\n",
    "\n",
    "print(\"New graph data successfully added to Neo4j!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
