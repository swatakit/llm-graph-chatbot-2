{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to GraphDocument and insert into Neo4j -- Custom System Prompt\n",
    "\n",
    "- With help from LLM but we only limited to small amount of data\n",
    "- Let LLM create graph schema with `custom system prompt`, *tailored for AML json data*\n",
    "- We only show here an example of creating schema of `EntityType=\"Individual\"`, the reader is encourage to repeat the example for `EntityType=\"Entity\"` as excercise\n",
    "\n",
    "- **Why the Default `system_prompt` Doesn't Work for Our Data:**\n",
    "  - The default system prompt in `LLMGraphTransformer` instructs the LLM to use **human names** as `id` values.\n",
    "  - **This is not suitable for our data** since we prefer using `EntityID` as the unique identifier.\n",
    "  - Using names as `id` can cause **inconsistencies** and **duplicate nodes**, especially when dealing with aliases or name variations.\n",
    "  - To ensure a **structured and unique graph**, we override this behavior by explicitly setting `EntityID` as the primary identifier.\n",
    "  - You can find the full default system prompt [here](https://python.langchain.com/api_reference/_modules/langchain_experimental/graph_transformers/llm.html#LLMGraphTransformer).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "load_dotenv('../.env',override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old graph deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 50/50 [02:19<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New graph data successfully added to Neo4j!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "\n",
    "# Initialize Neo4jGraph (LangChain handles the connection)\n",
    "graph = Neo4jGraph(url=NEO4J_URI,username=NEO4J_USER,password=NEO4J_PASSWORD,enhanced_schema=True)\n",
    "\n",
    "\n",
    "# **Step 1: Delete old graph before inserting new data**\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(\"Old graph deleted.\")\n",
    "\n",
    "# Define allowed nodes and relationships \n",
    "allowed_nodes = [\"Person\", \"Alias\", \"Address\", \"Program\", \"IdentityDocument\"]\n",
    "allowed_relationships = [\"HAS_ALIAS\", \"HAS_ADDRESS\",\"SANCTIONED_BY\", \"HAS_DOCUMENT\" ]\n",
    "\n",
    "# Define system prompt\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "\n",
    "# Knowledge Graph Extraction Instructions for GPT-4\n",
    "## 1. Overview\n",
    "You are an advanced AI system specializing in transforming structured data into a **graph-based knowledge representation**. \n",
    "Your goal is to extract **entities (nodes)** and **relationships (edges)** from the provided data.\n",
    "\n",
    "### 2. Allowed **Node Types**\n",
    "Use only these entity types as **nodes**:\n",
    "- **Person** → Represents an individual identified by `EntityID`.\n",
    "- **Alias** → Represents alternative names of a **Person**.\n",
    "- **Address** → Represents geographical locations (e.g., country, city).\n",
    "- **Sanction** → Represents a sanction action against a **Person**.\n",
    "- **Program** → Represents the sanction program associated with the **Sanction**.\n",
    "- **IdentityDocument** → Represents any official documents or listings associated with the person.\n",
    "\n",
    "\n",
    "### 3. Allowed **Relationships**\n",
    "Use only these **relationships** to connect nodes:\n",
    "- **HAS_ALIAS** → `(Person) -[:HAS_ALIAS]-> (Alias)`\n",
    "- **HAS_ADDRESS** → `(Person) -[:HAS_ADDRESS]-> (Address)`\n",
    "- **SANCTIONED_BY** → `(Person) -[:SANCTIONED_BY {{santion_type: \"Block\"}}]-> (Program)`\n",
    "- **HAS_DOCUMENT** → `(Person) -[:HAS_DOCUMENT]-> (IdentityDocument)`\n",
    "\n",
    "\n",
    "### 4. **How to Extract Nodes and Relationships**\n",
    "#### 🟢 **Person Nodes**\n",
    "- Extract a **Person** node using:\n",
    "  - **EntityID** (Unique identifier)\n",
    "  - **Full Name (Primary Name)**\n",
    "  - **First Name** (if available)\n",
    "  - **Last Name** (if available)\n",
    "  - **Gender** (if available)\n",
    "  - **Birthdate** (if available)\n",
    "  - **Place of Birth** (if available)\n",
    "  - **Nationality Country** (if available)\n",
    "  - **EntityType** (e.g., `\"Individual\"`, `\"Entity\"`, etc.)\n",
    "  - **Title** (if available, e.g., `\"Director of Organization XYZ\"`)\n",
    "  - ❌ DO NOT use a generic `Entity` label.\n",
    "\n",
    "#### 🟢 **Alias Nodes**\n",
    "- If a **Person** has multiple names (`IsPrimary=false`), store **non-primary names** as **Alias** nodes.\n",
    "- Ensure all **Alias** nodes use `fullName` as the attribute key, instead of `aliasName`.\n",
    "- Link them with **HAS_ALIAS**: (Person) -[:HAS_ALIAS]-> (Alias)\n",
    "\n",
    "#### 🟢 **Address Nodes**\n",
    "- If an **Address** exists, create an **Address** node.\n",
    "  - ❌ DO NOT use a generic `Entity` label.\n",
    "\n",
    "#### 🟢 **Alias Nodes**\n",
    "\n",
    "- If a **Person** has multiple names (`IsPrimary=false`), store **non-primary names** as **Alias** nodes.\n",
    "- Ensure all **Alias** nodes use:\n",
    "  - **Full Name** (`fullName` as the attribute key, instead of `aliasName`)\n",
    "  - **First Name** (if available)\n",
    "  - **Last Name** (if available)\n",
    "- Link them with **HAS_ALIAS**: `(Person) -[:HAS_ALIAS]-> (Alias)`\n",
    "\n",
    "#### 🟢 **Address Nodes**\n",
    "\n",
    "- If an **Address** exists, create an **Address** node with attributes:\n",
    "  - **Country** (e.g., `\"Colombia\"`)\n",
    "  - **City** (if available, e.g., `\"Cartago\"`)\n",
    "  - **Address** (if available, e.g., `\"Carrera 4 No. 16-04 apt. 303\"`)\n",
    "  - ❌ DO NOT use `location` as an attribute.\n",
    "- Link it to **Person** with **HAS_ADDRESS**: (Person) -[:HAS_ADDRESS]-> (Address)\n",
    "\n",
    "#### 🟢 **Sanction Nodes**\n",
    "- Extract a **Sanction** node for every **sanction program** under `Sanctions.Programs`.\n",
    "- Link it to **Person** using **SANCTIONED_BY**: (Person) -[:SANCTIONED_BY]-> (Sanction)\n",
    "\n",
    "#### 🟢 **Program Nodes**\n",
    "- Ensure that **all Program nodes** use only the attribute `name` for consistency.\n",
    "- If `programName` or `value` exists, rename it to `name`.\n",
    "\n",
    "### 5. **Coreference Resolution (Avoid Duplication)**\n",
    "- **Ensure each person is uniquely identified** by their `EntityID`—never create duplicate persons.\n",
    "- **Reuse existing Alias,and Address** when appropriate.\n",
    "\n",
    "\n",
    "Strictly adhere to these guidelines.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Define ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"Extract entities and relationships from the following data: {input}\")\n",
    "], template_format=\"f-string\")\n",
    "\n",
    "# LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    prompt=chat_prompt,\n",
    "    allowed_nodes=allowed_nodes,\n",
    "    allowed_relationships=allowed_relationships,\n",
    "    node_properties=True,\n",
    "    relationship_properties=True,\n",
    ")\n",
    "\n",
    "# Load JSON data\n",
    "with open(\"ofac_data_small.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)[\"individuals\"]\n",
    "\n",
    "# Function to process text\n",
    "def process_text(text: str):\n",
    "    doc = Document(page_content=text)\n",
    "    return llm_transformer.convert_to_graph_documents([doc])\n",
    "\n",
    "# Transform data using LLMGraphTransformer with parallelization\n",
    "graph_documents = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_text, json.dumps(entity)) for entity in data]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing documents\"):\n",
    "        graph_documents.extend(future.result())\n",
    "\n",
    "# **Step 2: Insert new graph data**\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=False, include_source=False)\n",
    "\n",
    "print(\"New graph data successfully added to Neo4j!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
